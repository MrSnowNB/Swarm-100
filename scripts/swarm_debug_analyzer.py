#!/usr/bin/env python3
"""
---
script: swarm_debug_analyzer.py
purpose: Debug analyzer for Swarm-100 agent interactions and coordination failures
framework: Standalone debugging tool with log correlation and failure detection
generated by: Grok Reasoning Analysis (Phase 3: Debugging Integration)
status: operational - integrates with existing logging infrastructure
created: 2025-10-18
---
**Debugging Integration Strategy:**
This script implements Grok's reasoning capabilities for analyzing multi-agent interactions.
It provides automated log correlation, failure pattern detection, and debugging recommendations
to identify coordination failures before they cascade through the entire swarm.
"""

import os
import glob
import re
import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set
from collections import defaultdict, Counter
import json
import argparse
import logging
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class LogEntry:
    timestamp: datetime
    agent_id: str
    gpu_id: int
    level: str
    message: str
    error_type: Optional[str] = None
    coordination_failures: Optional[List[str]] = None


@dataclass
class CoordinationFailure:
    failure_type: str
    severity: str  # LOW, MEDIUM, HIGH, CRITICAL
    affected_agents: List[str]
    timestamp: datetime
    description: str
    root_cause: str
    grok_recommendations: List[str]


@dataclass
class SwarmDebugReport:
    analysis_period: Tuple[datetime, datetime]
    total_agents: int
    total_log_entries: int
    coordination_failures: List[CoordinationFailure]
    agent_health_scores: Dict[str, float]  # 0-100 scale
    network_topology_issues: List[str]
    gpu_saturation_events: List[str]
    ollama_service_disruptions: List[str]
    overall_swarm_health_score: float


class SwarmDebugAnalyzer:
    """
    Advanced debugging analyzer for Swarm-100 multi-agent interactions.
    Uses log correlation and pattern recognition to identify coordination failures.
    """

    def __init__(self, logs_dir: str = "logs"):
        self.logs_dir = Path(logs_dir)
        self.parsed_logs: Dict[str, List[LogEntry]] = {}
        self.coordination_patterns = {
            'timeout_waiting_for_response': re.compile(r'Agent (\w+_gp\d_\d+) timed out waiting for response from (\w+_gp\d_\d+)'),
            'message_loss': re.compile(r'Message (\w+) lost while routing to (\w+_gp\d_\d+)'),
            'gossip_starvation': re.compile(r'Agent (\w+_gp\d_\d+) has no neighbors in gossip network'),
            'memory_exhaustion': re.compile(r'Memory pool exhausted.*(\w+_gp\d_\d+)'),
            'ollama_query_failure': re.compile(r'Ollama.*returned.*([45]\d\d).*for query'),
            'consensus_timeout': re.compile(r'Consensus failed.*timeout.*group.*(\w+)'),
            'network_isolation': re.compile(r'Agent (\w+_gp\d_\d+) isolated from network'),
            'gpu_resource_starvation': re.compile(r'CUDA.*insufficient resources.*GPU (\d)')
        }

    def load_and_parse_logs(self, hours_back: int = 24) -> int:
        """Load and parse swarm logs for analysis"""
        cutoff_time = datetime.now() - timedelta(hours=hours_back)
        total_entries = 0

        # Parse swarm manager log
        swarm_manager_log = self.logs_dir / "swarm_manager.log"
        if swarm_manager_log.exists():
            self.parsed_logs['swarm_manager'] = self._parse_swarm_manager_log(swarm_manager_log, cutoff_time)
            total_entries += len(self.parsed_logs['swarm_manager'])

        # Parse individual GPU logs
        gpu_dirs = list(self.logs_dir.glob("gpu_*"))
        for gpu_dir in gpu_dirs:
            gpu_id = int(gpu_dir.name.split('_')[1])
            bot_logs = list(gpu_dir.glob("*.log"))

            for bot_log in bot_logs:
                agent_id = bot_log.stem  # filename without .log
                self.parsed_logs[agent_id] = self._parse_bot_log(bot_log, gpu_id, cutoff_time)
                total_entries += len(self.parsed_logs[agent_id])

        logger.info(f"Loaded {total_entries} log entries from {len(self.parsed_logs)} sources")
        return total_entries

    def _parse_swarm_manager_log(self, log_file: Path, cutoff_time: datetime) -> List[LogEntry]:
        """Parse the swarm manager log"""
        entries = []
        try:
            with open(log_file, 'r') as f:
                for line in f:
                    entry = self._parse_log_line(line, 'swarm_manager', -1, cutoff_time)
                    if entry:
                        entries.append(entry)
        except Exception as e:
            logger.error(f"Error parsing swarm manager log: {e}")
        return entries

    def _parse_bot_log(self, log_file: Path, gpu_id: int, cutoff_time: datetime) -> List[LogEntry]:
        """Parse individual bot logs"""
        entries = []
        agent_id = log_file.stem

        try:
            with open(log_file, 'r') as f:
                for line in f:
                    entry = self._parse_log_line(line, agent_id, gpu_id, cutoff_time)
                    if entry:
                        entries.append(entry)
        except Exception as e:
            logger.error(f"Error parsing bot log {log_file}: {e}")
        return entries

    def _parse_log_line(self, line: str, agent_id: str, gpu_id: int, cutoff_time: datetime) -> Optional[LogEntry]:
        """Parse a single log line"""
        # Parse log format: [Bot-bot_00_01] 2025-10-18 22:30:15 - Health check passed - Stats: {...}
        log_pattern = r'\[Bot-(\w+)\]\s+(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}).*\s-\s(.+)'
        match = re.search(log_pattern, line)

        if not match:
            return None

        agent_name, timestamp_str, message = match.groups()

        try:
            timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
        except ValueError:
            return None

        if timestamp < cutoff_time:
            return None

        # Determine log level from message content
        level = 'INFO'
        if 'ERROR' in message or '✗' in message:
            level = 'ERROR'
        elif 'WARNING' in message or 'failed' in message.lower():
            level = 'WARNING'

        # Extract error type using coordination patterns
        error_type = None
        coordination_failures = []

        for pattern_name, pattern in self.coordination_patterns.items():
            matches = pattern.findall(message)
            if matches:
                error_type = pattern_name
                coordination_failures.extend(matches)

        return LogEntry(
            timestamp=timestamp,
            agent_id=agent_name,
            gpu_id=gpu_id,
            level=level,
            message=message,
            error_type=error_type,
            coordination_failures=coordination_failures
        )

    def analyze_coordination_failures(self) -> List[CoordinationFailure]:
        """Analyze logs for coordination failures using Grok's reasoning patterns"""
        failures = []

        # Group errors by time windows (5-minute windows)
        time_windows = self._group_errors_by_time_windows()

        # Analyze each time window for patterns
        for window_start, window_errors in time_windows.items():
            window_failures = self._analyze_error_window(window_start, window_errors)
            failures.extend(window_failures)

        # Look for cascade patterns (failures that trigger more failures)
        cascade_failures = self._identify_cascade_patterns(failures)
        failures.extend(cascade_failures)

        # Deduplicate and sort by severity/timestamp
        unique_failures = self._deduplicate_failures(failures)
        unique_failures.sort(key=lambda x: (x.severity, x.timestamp), reverse=True)

        return unique_failures

    def _group_errors_by_time_windows(self) -> Dict[datetime, List[LogEntry]]:
        """Group errors by 5-minute time windows"""
        windows = defaultdict(list)

        for agent_logs in self.parsed_logs.values():
            for entry in agent_logs:
                if entry.level in ('ERROR', 'WARNING'):
                    # Round to nearest 5-minute window
                    window_start = entry.timestamp.replace(
                        minute=entry.timestamp.minute // 5 * 5,
                        second=0,
                        microsecond=0
                    )
                    windows[window_start].append(entry)

        return dict(windows)

    def _analyze_error_window(self, window_start: datetime, window_errors: List[LogEntry]) -> List[CoordinationFailure]:
        """Analyze a 5-minute window of errors for coordination patterns"""
        failures = []

        # Count error types
        error_counts = Counter(entry.error_type for entry in window_errors if entry.error_type)

        # Identify coordination patterns
        affected_agents = list(set(entry.agent_id for entry in window_errors))

        # Ollama overload detection
        ollama_errors = [e for e in window_errors if e.error_type == 'ollama_query_failure']
        if len(ollama_errors) > 10:  # Arbitrary threshold
            failures.append(CoordinationFailure(
                failure_type='ollama_overload_cascade',
                severity='HIGH',
                affected_agents=list(set(e.agent_id for e in ollama_errors)),
                timestamp=window_start,
                description=f'Ollama service overloaded with {len(ollama_errors)} failed queries in 5-minute window',
                root_cause='Single Ollama instance cannot handle concurrent requests from 100 agents',
                grok_recommendations=[
                    'Deploy separate Ollama instances per GPU (11434-11437 ports)',
                    'Implement request queuing with priority classification',
                    'Add circuit breaker pattern to prevent cascade failures'
                ]
            ))

        # Gossip network isolation
        isolation_errors = [e for e in window_errors if e.error_type == 'gossip_starvation']
        if isolation_errors:
            failures.append(CoordinationFailure(
                failure_type='gossip_network_isolation',
                severity='CRITICAL',
                affected_agents=[e.agent_id for e in isolation_errors],
                timestamp=window_start,
                description=f'{len(isolation_errors)} agents experiencing gossip network isolation',
                root_cause='Missing gossip communication infrastructure - agents cannot discover peers',
                grok_recommendations=[
                    'Implement p2p messaging layer with gossip_hops:4 and fanout:5',
                    'Add neighbor discovery protocol during agent startup',
                    'Configure entry nodes for isolated GPUs to bootstrap connectivity'
                ]
            ))

        # Memory exhaustion cascade
        memory_errors = [e for e in window_errors if e.error_type == 'memory_exhaustion']
        if len(memory_errors) > 5:
            gpu_counts = Counter(e.gpu_id for e in memory_errors if e.gpu_id >= 0)
            for gpu_id, count in gpu_counts.items():
                if count >= 3:  # Multiple agents on same GPU
                    failures.append(CoordinationFailure(
                        failure_type='gpu_memory_cascade',
                        severity='HIGH',
                        affected_agents=[e.agent_id for e in memory_errors if e.gpu_id == gpu_id],
                        timestamp=window_start,
                        description=f'Memory exhaustion cascade on GPU {gpu_id} affecting {count} agents',
                        root_cause=f'Insufficient VRAM management - gpu_memory_fraction:0.95 exceeded',
                        grok_recommendations=[
                            'Reduce gpu_memory_fraction to 0.85 for safety margin',
                            'Implement memory quota enforcement per agent',
                            'Add memory defragmentation and cleanup routines'
                        ]
                    ))

        # Response timeout cascade
        timeout_errors = [e for e in window_errors if e.error_type == 'timeout_waiting_for_response']
        if len(timeout_errors) > 15:
            requester_agents = set(e.agent_id for e in timeout_errors)
            target_agents = set()
            for e in timeout_errors:
                if e.coordination_failures:
                    targets = [f for f in e.coordination_failures if f.startswith('bot_')]
                    target_agents.update(targets)

            failures.append(CoordinationFailure(
                failure_type='response_timeout_cascade',
                severity='MEDIUM',
                affected_agents=list(requester_agents | target_agents),
                timestamp=window_start,
                description=f'{len(timeout_errors)} timeout events indicating communication breakdown',
                root_cause='Network latency or agent failures disrupting message flow',
                grok_recommendations=[
                    'Increase request timeout values (current: 30s)',
                    'Implement retry logic with exponential backoff',
                    'Add health checking before sending requests'
                ]
            ))

        return failures

    def _identify_cascade_patterns(self, failures: List[CoordinationFailure]) -> List[CoordinationFailure]:
        """Identify cascade patterns where one failure triggers others"""
        cascades = []

        # Look for GPU→Agent→Network cascades
        gpu_failures = [f for f in failures if 'gpu' in f.failure_type]
        memory_failures = [f for f in failures if 'memory' in f.failure_type]
        network_failures = [f for f in failures if 'gossip' in f.failure_type or 'network' in f.failure_type]

        if gpu_failures and memory_failures and network_failures:
            # Find overlapping time windows
            cascade_times = set()
            cascade_times.update(f.timestamp for f in gpu_failures)
            cascade_times.update(f.timestamp for f in memory_failures)
            cascade_times.update(f.timestamp for f in network_failures)

            if len(cascade_times) <= 3:  # Events clustered in time
                all_affected = set()
                all_affected.update(*(set(f.affected_agents) for f in gpu_failures))
                all_affected.update(*(set(f.affected_agents) for f in memory_failures))
                all_affected.update(*(set(f.affected_agents) for f in network_failures))

                cascades.append(CoordinationFailure(
                    failure_type='failure_cascade_critical',
                    severity='CRITICAL',
                    affected_agents=list(all_affected),
                    timestamp=min(cascade_times),
                    description=f'Critical failure cascade: GPU→Memory→Network affecting {len(all_affected)} agents',
                    root_cause='Compounding failures creating system-wide instability',
                    grok_recommendations=[
                        'Implement circuit breaker to isolate failing components',
                        'Add automatic system reset protocols for cascade conditions',
                        'Configure isolated execution environments per GPU',
                        'Implement progressive degradation rather than total failure'
                    ]
                ))

        return cascades

    def _deduplicate_failures(self, failures: List[CoordinationFailure]) -> List[CoordinationFailure]:
        """Remove duplicate/similar failures within short time windows"""
        if not failures:
            return failures

        # Sort by timestamp
        failures.sort(key=lambda x: x.timestamp)

        deduplicated = []
        last_failure = None

        for failure in failures:
            if (last_failure is None or
                last_failure.failure_type != failure.failure_type or
                abs((failure.timestamp - last_failure.timestamp).total_seconds()) > 300):  # 5 min window
                deduplicated.append(failure)
                last_failure = failure
            elif failure.severity in ('HIGH', 'CRITICAL') and last_failure.severity not in ('HIGH', 'CRITICAL'):
                # Keep higher severity failure
                deduplicated[-1] = failure
                last_failure = failure

        return deduplicated

    def calculate_agent_health_scores(self) -> Dict[str, float]:
        """Calculate health scores for each agent based on log analysis"""
        health_scores = {}

        for agent_id, logs in self.parsed_logs.items():
            if agent_id == 'swarm_manager' or not logs:
                continue

            # Calculate metrics
            total_entries = len(logs)
            error_entries = len([l for l in logs if l.level == 'ERROR'])
            warning_entries = len([l for l in logs if l.level == 'WARNING'])
            successful_interactions = len([l for l in logs if 'successful' in l.message.lower()])

            # Weight factors
            error_rate = error_entries / max(total_entries, 1)
            health_score = 100.0
            health_score -= error_rate * 50  # Errors reduce score significantly
            health_score -= (warning_entries / max(total_entries, 1)) * 20  # Warnings less impact
            health_score += (successful_interactions / max(total_entries, 1)) * 30  # Successes boost

            # Ensure bounds
            health_score = max(0.0, min(100.0, health_score))
            health_scores[agent_id] = round(health_score, 1)

        return health_scores

    def generate_swarm_health_report(self, hours_back: int = 24) -> SwarmDebugReport:
        """Generate comprehensive swarm health report"""
        if not self.parsed_logs:
            self.load_and_parse_logs(hours_back)

        # Calculate time range
        all_timestamps = []
        for logs in self.parsed_logs.values():
            all_timestamps.extend([e.timestamp for e in logs])

        if all_timestamps:
            start_time = min(all_timestamps)
            end_time = max(all_timestamps)
        else:
            start_time = end_time = datetime.now()

        # Analyze coordination failures
        coordination_failures = self.analyze_coordination_failures()

        # Calculate agent health scores
        agent_health_scores = self.calculate_agent_health_scores()

        # Count total entries
        total_entries = sum(len(logs) for logs in self.parsed_logs.values())

        # Get GPU count from configuration
        gpu_count = len(list(self.logs_dir.glob("gpu_*")))

        # Placeholder for additional analysis (would be implemented)
        network_issues = ["Gossip protocol not implemented"]
        gpu_saturation_events = []
        ollama_disruptions = []

        # Calculate overall swarm health score
        if agent_health_scores:
            avg_agent_health = sum(agent_health_scores.values()) / len(agent_health_scores)
            failure_penalty = len([f for f in coordination_failures if f.severity in ('HIGH', 'CRITICAL')]) * 5
            overall_score = max(0, avg_agent_health - failure_penalty)
        else:
            overall_score = 0

        return SwarmDebugReport(
            analysis_period=(start_time, end_time),
            total_agents=len(agent_health_scores),
            total_log_entries=total_entries,
            coordination_failures=coordination_failures,
            agent_health_scores=agent_health_scores,
            network_topology_issues=network_issues,
            gpu_saturation_events=gpu_saturation_events,
            ollama_service_disruptions=ollama_disruptions,
            overall_swarm_health_score=round(overall_score, 1)
        )

    def print_debug_report(self, report: SwarmDebugReport):
        """Print formatted debug report"""
        print("\n" + "="*80)
        print("🐛 SWARM-100 DEBUG ANALYSIS REPORT")
        print("="*80)
        print(f"📊 Analysis Period: {report.analysis_period[0]} to {report.analysis_period[1]}")
        print(f"🤖 Total Agents Analyzed: {report.total_agents}")
        print(f"📝 Total Log Entries: {report.total_log_entries}")
        print(".1f")

        if report.coordination_failures:
            print(f"\n🚨 COORDINATION FAILURES DETECTED ({len(report.coordination_failures)})")
            print("-" * 40)

            for i, failure in enumerate(report.coordination_failures[:10], 1):  # Top 10
                severity_icon = {'LOW': '⚪', 'MEDIUM': '🟡', 'HIGH': '🟠', 'CRITICAL': '🔴'}
                print(f"{i}. {severity_icon.get(failure.severity, '❓')} {failure.failure_type}")
                print(f"   Severity: {failure.severity}")
                print(f"   Affected: {len(failure.affected_agents)} agents")
                print(f"   Time: {failure.timestamp}")
                print(f"   Root Cause: {failure.root_cause}")
                print(f"   🎯 Grok Recommendations:")
                for rec in failure.grok_recommendations[:3]:  # Top 3
                    print(f"      • {rec}")
                print()
        else:
            print("\n✅ NO COORDINATION FAILURES DETECTED")
        if report.agent_health_scores:
            print(f"\n🏥 AGENT HEALTH SCORES (TOP 10 BEST/WORST)")
            print("-" * 40)

            sorted_scores = sorted(report.agent_health_scores.items(), key=lambda x: x[1])
            worst_5 = sorted_scores[:5]
            best_5 = sorted_scores[-5:][::-1]

            print("📈 HEALTHIEST AGENTS:")
            for agent, score in best_5:
                health_icon = '❤️' if score > 95 else '💚' if score > 85 else '💛' if score > 75 else '🧡'
                print(".1f")

            print("\n📉 AGENTS NEEDING ATTENTION:")
            for agent, score in worst_5:
                health_icon = '🤒' if score < 50 else '🤧' if score < 70 else '🌡️'
                print(".1f")

        if report.overall_swarm_health_score < 70:
            print(f"\n🚨 CRITICAL: Overall swarm health score is low ({report.overall_swarm_health_score:.1f}/100)")
            print("   Immediate intervention required!")
        elif report.overall_swarm_health_score < 85:
            print(f"\n⚠️  WARNING: Swarm health needs attention ({report.overall_swarm_health_score:.1f}/100)")
        else:
            print(f"\n✅ SWARM IS HEALTHY ({report.overall_swarm_health_score:.1f}/100)")

        print("\n" + "="*80)
        print("🐙 Generated by Grok Reasoning Analysis - Phase 3")
        print("="*80)


def main():
    parser = argparse.ArgumentParser(description='Swarm-100 Debug Analyzer')
    parser.add_argument('--hours', type=int, default=24, help='Hours of logs to analyze (default: 24)')
    parser.add_argument('--logs-dir', type=str, default='logs', help='Logs directory (default: logs)')
    parser.add_argument('--output-json', type=str, help='Output report as JSON file')
    args = parser.parse_args()

    analyzer = SwarmDebugAnalyzer(args.logs_dir)

    print("🔍 Starting Swarm-100 debug analysis...")
    print(f"   📂 Analyzing logs from: {args.logs_dir}")

    # Load and analyze logs
    total_entries = analyzer.load_and_parse_logs(args.hours)
    if total_entries == 0:
        print("❌ No log entries found in the specified time range. Run the swarm first!")
        return

    # Generate comprehensive report
    report = analyzer.generate_swarm_health_report(args.hours_back)

    # Print report
    analyzer.print_debug_report(report)

    # Optional JSON export
    if args.output_json:
        with open(args.output_json, 'w') as f:
            json.dump(asdict(report), f, indent=2, default=str)
        print(f"\n💾 Report exported to: {args.output_json}")

    # Exit codes based on health
    if report.overall_swarm_health_score < 50:
        exit(2)  # Critical
    elif report.overall_swarm_health_score < 80:
        exit(1)  # Warning
    else:
        exit(0)  # Success


if __name__ == '__main__':
    main()
